#!/usr/bin/env -S uv run --script
# /// script
# dependencies = [
#   "typer>=0.12",
#   "httpx>=0.27",
#   "google-auth>=2.27",
#   "google-auth-oauthlib>=1.2",
#   "rich>=13.7"
# ]
# ///

"""Minimal, elegant Gmail search CLI."""

import asyncio
import httpx
import json
import typer
from datetime import timezone
from email.utils import parsedate_to_datetime
from typing import Any, Dict, List, Optional, Sequence
from email.utils import parseaddr
from rich.console import Console
from pathlib import Path
from google_oauth import ensure_token, api

HEADERS = ["Date", "From", "To", "Subject"]
GMAIL_SCOPES = ["https://www.googleapis.com/auth/gmail.readonly"]
GMAIL_TOKEN_FILE = Path("~/.config/sanand-scripts/token.gmail.json").expanduser()


async def list_messages(
    client: httpx.AsyncClient, q: str, page_size: int, limit: int
) -> List[Dict[str, Any]]:
    """List message refs up to limit with internal pagination."""
    items: List[Dict[str, Any]] = []
    token: Optional[str] = None
    while len(items) < limit:
        take = min(page_size, limit - len(items))
        params = {"q": q, "maxResults": take}
        if token:
            params["pageToken"] = token
        data = await api(client, "GET", "/messages", params=params)
        msgs = data.get("messages", [])
        if not msgs:
            return items
        items += msgs
        token = data.get("nextPageToken")
        if not token:
            return items
    return items


async def get_metadata(client: httpx.AsyncClient, msg_id: str) -> Dict[str, Any]:
    """Fetch per-message metadata only with selected headers."""
    params = {"format": "metadata"}
    for h in HEADERS:
        params.setdefault("metadataHeaders", []).append(h)
    return await api(client, "GET", f"/messages/{msg_id}", params=params)


async def gather_details(
    client: httpx.AsyncClient, refs: Sequence[Dict[str, Any]], concurrency: int = 16
) -> List[Dict[str, Any]]:
    """Fetch details concurrently with a semaphore."""
    sem = asyncio.Semaphore(concurrency)

    async def one(ref: Dict[str, Any]) -> Dict[str, Any]:
        async with sem:
            return await get_metadata(client, ref["id"])

    return await asyncio.gather(*[one(r) for r in refs])


def fmt_date(s: str) -> str:
    """Format RFC2822 date to yyyy-mm-dd hh:mm (local)."""
    if not s:
        return ""
    try:
        dt = parsedate_to_datetime(s)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt.astimezone().strftime("%Y-%m-%d %H:%M")
    except Exception:
        return s


FIELDS = {
    "id": lambda m, hm: m.get("id", ""),
    "date": lambda m, hm: fmt_date(hm.get("date", "")),
    "from": lambda m, hm: hm.get("from", ""),
    "email": lambda m, hm: parseaddr(hm.get("from", ""))[1],
    "to": lambda m, hm: hm.get("to", ""),
    "subject": lambda m, hm: hm.get("subject", ""),
    "snippet": lambda m, hm: m.get("snippet", ""),
    "labels": lambda m, hm: ",".join(m.get("labelIds", [])),
    "size": lambda m, hm: m.get("sizeEstimate", ""),
}


def to_row(m: Dict[str, Any], fields: Sequence[str]) -> Dict[str, Any]:
    """Convert Gmail message to selected fields."""
    hdrs = m.get("payload", {}).get("headers", [])
    hm = {h.get("name", "").lower(): h.get("value", "") for h in hdrs}
    return {k: FIELDS[k](m, hm) for k in fields if k in FIELDS}


def print_tsv(rows: List[Dict[str, Any]], fields: Sequence[str]) -> None:
    """Render TSV with header, colorized per column."""
    con = Console(highlight=False)
    con.print("\t".join(fields))
    c = ["cyan", "magenta", "green", "white", "blue", "yellow"]
    for r in rows:
        v = [str(r.get(f, "")) for f in fields]
        con.print("\t".join(f"[{c[i % len(c)]}]{x}[/{c[i % len(c)]}]" for i, x in enumerate(v)))


app = typer.Typer(add_completion=False, no_args_is_help=True, help="Search Gmail.")


def parse_fields(values: List[str]) -> List[str]:
    """Split --fields values by commas and/or whitespace."""
    if not values:
        return []
    tokens: List[str] = []
    for v in values:
        for part in v.replace(",", " ").split():
            tokens.append(part.strip())
    return tokens


@app.command(context_settings={"allow_extra_args": False, "ignore_unknown_options": False})
def main(
    q: str = typer.Argument("in:inbox", help="Gmail search query (Gmail search syntax)."),
    user_id: str = typer.Option("me", "--user", help="Gmail user: 'me' or email."),
    limit: int = typer.Option(20, "-n", "--limit", min=1, help="Total results to print."),
    fields: List[str] = typer.Option(
        ["date", "from", "subject", "snippet"],
        "--fields",
        help=(
            "Fields to print; repeat or separate with commas/spaces. "
            f"Valid: {', '.join(FIELDS.keys())}"
        ),
    ),
    json_out: bool = typer.Option(False, "--json", help="Emit JSON (items)."),
):
    """Search Gmail and print messages in a clean table or JSON.

    Examples:\n
    - gmail --limit 50 "from:example.com"  # list 50 recent inbox emails\n
    - gmail --fields date,email "subject:invoice"  # show date and only sender email\n
    - gmail --fields "date, from, subject" in:archive  # comma/space separated fields\n
    - gmail --json --fields "email subject" "has:attachment newer_than:1y"  # JSON output\n
    """
    if limit < 1:
        return

    tok = ensure_token(scopes=GMAIL_SCOPES, token_file=GMAIL_TOKEN_FILE)
    if not tok:
        return
    base = f"https://gmail.googleapis.com/gmail/v1/users/{user_id}"
    headers_http = {"Authorization": f"Bearer {tok}", "Accept": "application/json"}

    async def _run() -> None:
        async with httpx.AsyncClient(base_url=base, headers=headers_http, timeout=30) as client:
            page_size = limit if limit <= 500 else 500
            refs = await list_messages(client=client, q=q, page_size=page_size, limit=limit)
            if not refs:
                if json_out:
                    print(json.dumps({"items": []}))
                return

            details = await gather_details(client, refs)
            sel_fields = parse_fields(fields)
            rows = [to_row(m, sel_fields) for m in details]
            if json_out:
                print(json.dumps({"items": rows}, ensure_ascii=False))
                return
            print_tsv(rows, sel_fields)

    asyncio.run(_run())


if __name__ == "__main__":
    app()
